# AI-Powered Sign Language Recognition - Development Plan

## ğŸ“‹ Project Overview

**Topic:** AI-Powered Sign Language Recognition for Real-Time Translation
**Team:** 3 Developers
- **Ulzhan** - Frontend Developer (React)
- **Vlad** - Backend Developer (Python, MediaPipe)
- **Rakhat** - Backend Developer (Python, Gemini LLM)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND (React)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Camera     â”‚  â”‚  Video      â”‚  â”‚  Translated Text        â”‚  â”‚
â”‚  â”‚  Component  â”‚  â”‚  Preview    â”‚  â”‚  Display                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                                        â”‚
â”‚         â–¼ WebSocket / HTTP                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BACKEND (Python/FastAPI)                    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  MediaPipe Service (Vlad)                               â”‚    â”‚
â”‚  â”‚  - Hand landmark detection                              â”‚    â”‚
â”‚  â”‚  - Gesture classification                               â”‚    â”‚
â”‚  â”‚  - Sign sequence extraction                             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                      â”‚
â”‚                           â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  LLM Service (Rakhat)                                   â”‚    â”‚
â”‚  â”‚  - Gemini API integration                               â”‚    â”‚
â”‚  â”‚  - Sign â†’ Natural language conversion                   â”‚    â”‚
â”‚  â”‚  - Context management                                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
sign-language-translator/
â”œâ”€â”€ ğŸ“ frontend/                    # Ulzhan's workspace
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Camera/            # Webcam capture component
â”‚   â”‚   â”‚   â”œâ”€â”€ VideoPreview/      # Live video with landmarks
â”‚   â”‚   â”‚   â”œâ”€â”€ TranslationPanel/  # Display translated text
â”‚   â”‚   â”‚   â””â”€â”€ Controls/          # Start/Stop/Settings
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useWebSocket.ts    # WebSocket connection hook
â”‚   â”‚   â”‚   â””â”€â”€ useCamera.ts       # Camera access hook
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts             # API client
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts           # TypeScript interfaces
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ ğŸ“ backend/                     # Shared backend workspace
â”‚   â”œâ”€â”€ ğŸ“ media_pipe_service/      # Vlad's workspace
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ gesture_classifier.py
â”‚   â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”‚   â””â”€â”€ hand_processor.py
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ landmarks.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ llm_service/             # Rakhat's workspace
â”‚   â”‚   â”œâ”€â”€ clients/
â”‚   â”‚   â”‚   â””â”€â”€ gemini_client.py
â”‚   â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”‚   â””â”€â”€ sentence_builder.py
â”‚   â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â”‚   â””â”€â”€ session_manager.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ api_gateway/             # Shared: API routing
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ translation.py
â”‚   â”‚   â”‚   â””â”€â”€ websocket.py
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ main.py                 # FastAPI entry point
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ shared/                  # Shared utilities
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â””â”€â”€ schemas.py          # Pydantic models
â”‚       â””â”€â”€ utils/
â”‚           â””â”€â”€ config.py
â”‚
â”œâ”€â”€ ğŸ“ docker/                      # Docker configurations
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ frontend.Dockerfile
â”‚   â””â”€â”€ backend.Dockerfile
â”‚
â”œâ”€â”€ ğŸ“ docs/                        # Documentation
â”‚   â”œâ”€â”€ API.md
â”‚   â””â”€â”€ SETUP.md
â”‚
â””â”€â”€ Makefile                        # Easy local build commands
```

---

## ğŸ› ï¸ Tech Stack

### Frontend (Ulzhan)
| Component | Technology |
|-----------|------------|
| Framework | React 18 + TypeScript |
| Build Tool | Vite |
| UI Library | Tailwind CSS + shadcn/ui |
| State Management | Zustand |
| WebSocket | Native WebSocket API |
| Camera Access | MediaDevices API |

### Backend - MediaPipe Service (Vlad)
| Component | Technology |
|-----------|------------|
| Language | Python 3.10+ |
| Framework | FastAPI |
| Hand Detection | MediaPipe Hands |
| Gesture Classification | Custom classifier / MediaPipe Gesture |
| Communication | WebSocket for real-time |

### Backend - LLM Service (Rakhat)
| Component | Technology |
|-----------|------------|
| Language | Python 3.10+ |
| Framework | FastAPI |
| LLM | Google Gemini API |
| Context Management | In-memory / Redis (optional) |
| Communication | HTTP/REST |

### DevOps / Shared
| Component | Technology |
|-----------|------------|
| Containerization | Docker + Docker Compose |
| Process Manager | Concurrently (npm) |
| Environment | python-dotenv |

---

## ğŸ‘¥ Task Breakdown

### ğŸ”· Ulzhan (Frontend) - Week 1-2

#### Week 1: Setup & Camera
- [ ] Initialize React project with Vite + TypeScript
- [ ] Setup Tailwind CSS and shadcn/ui
- [ ] Create Camera component with MediaDevices API
- [ ] Implement video preview with recording indicator
- [ ] Add error handling for camera permissions

#### Week 2: UI & WebSocket
- [ ] Design main layout (video left, translation right)
- [ ] Create TranslationPanel component
- [ ] Implement WebSocket connection hook
- [ ] Add controls (Start/Stop translation, Clear text)
- [ ] Create loading/error states

**Deliverables:**
- Working camera capture
- WebSocket client ready
- UI components complete

---

### ğŸ”¶ Vlad (MediaPipe) - Week 1-2

#### Week 1: Setup & Hand Detection
- [ ] Setup Python virtual environment
- [ ] Install MediaPipe, OpenCV, FastAPI
- [ ] Create hand landmark detection module
- [ ] Extract 21 hand landmarks per frame
- [ ] Build landmark normalization (relative coordinates)

#### Week 2: Gesture Classification
- [ ] Create gesture classifier (start with basic signs: A-Z, 0-9)
- [ ] Build sign sequence buffer (collect multiple frames)
- [ ] Implement gesture-to-letter mapping
- [ ] Create WebSocket endpoint for real-time streaming
- [ ] Add confidence threshold filtering

**Deliverables:**
- MediaPipe service running locally
- WebSocket endpoint accepting video frames
- Returns detected signs as text stream

---

### ğŸ”¶ Rakhat (LLM Service) - Week 1-2

#### Week 1: Setup & Gemini Integration
- [ ] Setup Python virtual environment
- [ ] Create Gemini API client
- [ ] Implement prompt engineering for sign language
- [ ] Build basic sentence generation from sign sequences
- [ ] Add API endpoint for text translation

#### Week 2: Context & Polish
- [ ] Implement session-based context management
- [ ] Add grammar correction and natural language processing
- [ ] Create fallback for unrecognized signs
- [ ] Build health check endpoints
- [ ] Add request/response logging

**Deliverables:**
- LLM service running locally
- REST API accepting sign sequences
- Returns natural language sentences

---

## ğŸ”Œ API Contracts

### WebSocket: Frontend â†” MediaPipe Service

```javascript
// Connection
ws://localhost:8001/ws/sign-detection

// Client â†’ Server (send frame)
{
  "frame": "base64_encoded_image",  // JPEG frame from camera
  "timestamp": 1707151200
}

// Server â†’ Client (detected sign)
{
  "sign": "H",                      // Detected sign letter/gesture
  "confidence": 0.95,
  "timestamp": 1707151200,
  "hand_detected": true
}
```

### HTTP: MediaPipe Service â†” LLM Service

```python
# POST /api/v1/translate
Request:
{
    "sign_sequence": ["H", "E", "L", "L", "O"],
    "session_id": "uuid-123",
    "context": "previous sentence context"  # optional
}

Response:
{
    "translation": "Hello, how are you?",
    "confidence": 0.92,
    "session_id": "uuid-123",
    "suggestions": ["Hello there!", "Hello everyone!"]  # optional
}
```

### HTTP: Frontend â†” API Gateway

```typescript
// POST /api/v1/translate (batch mode, optional)
Request:
{
    "video_url": "uploaded_video_url"  // for recorded video translation
}

// GET /api/v1/health
Response:
{
    "status": "healthy",
    "services": {
        "media_pipe": "up",
        "llm": "up"
    }
}
```

---

## ğŸš€ Local Development Setup

### Prerequisites
- Node.js 18+
- Python 3.10+
- Docker (optional but recommended)
- Google Gemini API Key

### Quick Start (One Command)

```bash
# Clone and enter project
git clone <repo-url>
cd sign-language-translator

# Start everything with Docker (Recommended)
docker-compose up

# Or start locally with Make
make dev
```

### Manual Setup

#### 1. Backend Setup (Vlad & Rakhat)

```bash
# In separate terminals

# Terminal 1: MediaPipe Service (Vlad)
cd backend/media_pipe_service
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn main:app --reload --port 8001

# Terminal 2: LLM Service (Rakhat)
cd backend/llm_service
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
# Create .env file with GEMINI_API_KEY
uvicorn main:app --reload --port 8002

# Terminal 3: API Gateway (Shared)
cd backend/api_gateway
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload --port 8000
```

#### 2. Frontend Setup (Ulzhan)

```bash
cd frontend
npm install
npm run dev
```

### Access Points
- **Frontend:** http://localhost:5173
- **API Gateway:** http://localhost:8000
- **MediaPipe Service:** http://localhost:8001
- **LLM Service:** http://localhost:8002

---

## ğŸ”€ Development Workflow

### Branch Strategy

```
main (production-ready)
  â”œâ”€â”€ develop (integration branch)
  â”‚     â”œâ”€â”€ feature/ulzhan-camera-component
  â”‚     â”œâ”€â”€ feature/vlad-mediapipe-detection
  â”‚     â””â”€â”€ feature/rakhat-gemini-integration
```

### Git Workflow

```bash
# Each developer works on their feature branch
git checkout -b feature/ulzhan-camera-component

# Regular commits
git add .
git commit -m "feat: add camera component with permission handling"

# Push and create PR to develop branch
git push origin feature/ulzhan-camera-component
# Create Pull Request on GitHub
```

### Communication Protocol

1. **Daily Standups** (5 min): Share blockers and progress
2. **API Contract First**: Agree on interfaces before implementation
3. **Integration Day**: Mid-week sync to test integration
4. **End-of-Week Demo**: Show working features

---

## ğŸ“¦ Dependencies

### Frontend package.json
```json
{
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "zustand": "^4.4.0",
    "tailwindcss": "^3.4.0",
    "lucide-react": "^0.300.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.0",
    "typescript": "^5.3.0",
    "vite": "^5.0.0"
  }
}
```

### Backend requirements.txt (MediaPipe)
```
fastapi==0.109.0
uvicorn[standard]==0.27.0
mediapipe==0.10.9
opencv-python==4.9.0.80
numpy==1.26.3
websockets==12.0
python-multipart==0.0.6
pydantic==2.5.0
```

### Backend requirements.txt (LLM)
```
fastapi==0.109.0
uvicorn[standard]==0.27.0
google-generativeai==0.3.2
python-dotenv==1.0.0
httpx==0.26.0
pydantic==2.5.0
redis==5.0.1  # optional for context
```

---

## ğŸ¯ Milestones

### Week 1: Foundation
- [ ] All developers have local environment running
- [ ] Ulzhan: Camera working, can capture video
- [ ] Vlad: MediaPipe detecting hand landmarks
- [ ] Rakhat: Gemini API responding to requests

### Week 2: Integration
- [ ] Frontend â†” MediaPipe connected via WebSocket
- [ ] MediaPipe â†” LLM connected via HTTP
- [ ] End-to-end: Sign â†’ Detected Letters â†’ Natural Sentence
- [ ] Basic UI showing real-time translation

### Week 3: Polish (Optional)
- [ ] Improve gesture accuracy
- [ ] Better context management
- [ ] UI/UX refinements
- [ ] Error handling and edge cases

---

## ğŸ”§ Troubleshooting

### Common Issues

1. **Camera not accessible**
   - Check browser permissions
   - Ensure HTTPS or localhost (required for camera)

2. **MediaPipe not detecting hands**
   - Ensure good lighting
   - Check camera resolution (min 640x480)

3. **Gemini API errors**
   - Verify API key in .env
   - Check API rate limits

4. **WebSocket connection fails**
   - Verify all services are running
   - Check CORS settings

---

## ğŸ“š Resources

### MediaPipe
- [MediaPipe Hands](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker)
- [Python Setup Guide](https://developers.google.com/mediapipe/solutions/setup_python)

### Gemini API
- [Gemini API Docs](https://ai.google.dev/docs)
- [Python Quickstart](https://ai.google.dev/tutorials/python_quickstart)

### React + WebSocket
- [MDN WebSocket API](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [React useWebSocket Hook](https://github.com/robtaussig/react-use-websocket)

---

## âœ… Success Criteria

- [ ] User can open web app, allow camera, and see video
- [ ] When user makes sign language gestures, hand landmarks appear
- [ ] Detected signs stream in real-time
- [ ] Natural language translation appears after sign sequence
- [ ] Project builds and runs with single command (`make dev` or `docker-compose up`)

---

*Plan created for AI Sign Language Recognition Team*
*Last updated: 2026-02-08*
